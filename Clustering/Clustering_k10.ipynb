{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ef4457",
   "metadata": {},
   "source": [
    "## CLUSTERING AS A PRE-PROCESSING STEP (k=10)-\n",
    "\n",
    "#### Since the models directly done on the Kaggle dataset didn't perform well, we will do another clustering for the hotels and check the models on the newly clustered data.\n",
    "***\n",
    "### 1. Load the cleaned original train dataset-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d790c574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "path_train_final ='F:/AML/Project/clean dataset/FinalExpedia_set_cleaned/Train_set_cleaned.csv'\n",
    "\n",
    "train_set=pd.read_csv(path_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b7f4e7-182f-4784-8b6b-a28a57e774b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2512931, 39)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a39660",
   "metadata": {},
   "source": [
    "### 2. Clustering-\n",
    "#### Elbow method which we saw earlier gave optimum k=20.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517d3e6",
   "metadata": {},
   "source": [
    "##### KMeans algorithm is used for creating the optimum no.of clusters (k=20) and we have seen this performance already. Now, let us check with k=10 to understand how accuracy is with diff. cluster sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00223c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    954068\n",
       "4    542922\n",
       "1    250698\n",
       "3    203284\n",
       "9    200150\n",
       "5    149606\n",
       "2     97591\n",
       "8     46057\n",
       "7     46001\n",
       "6     22554\n",
       "Name: new_hotel_cluster, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Kmean = KMeans(n_clusters=10).fit(train_set[['srch_destination_id', 'srch_destination_type_id', 'cnt',\n",
    "       'hotel_continent', 'hotel_country', 'hotel_market']])\n",
    "\n",
    "new_clusters=Kmean.labels_\n",
    "train_set[\"new_hotel_cluster\"]=new_clusters #update train_set with new hotel clusters\n",
    "train_set[\"new_hotel_cluster\"].value_counts() #new cluster distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98421383",
   "metadata": {},
   "source": [
    "#### Split this train set to train and test datasets in 80:20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e6eeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictors = [c for c in train_set.columns if c not in [\"new_hotel_cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca9f8ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_set[predictors], train_set[\"new_hotel_cluster\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6df8a-741b-4a2c-8d7f-0bb3633fef8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Using models-\n",
    "#### Apply the classification models on this clustered data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafacc53",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST-\n",
    "***\n",
    "##### a. with 50 binary trees-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f181575f-69c8-4485-bb41-6415fe0ac202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, min_weight_fraction_leaf=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ef0681a-0516-41ee-bce5-c8e26ea99ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5999617976589128\n",
      "Precision: 0.5999617976589128\n",
      "Recall: 0.5999617976589128\n",
      "F1 Score: 0.5999617976589128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Precision:\",precision_score(y_test, preds, average=\"micro\"))\n",
    "print(\"Recall:\",recall_score(y_test, preds,  average=\"micro\"))\n",
    "print(\"F1 Score:\",f1_score(y_test, preds,  average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4600a",
   "metadata": {},
   "source": [
    "##### b. with 100 binary trees-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cc0c95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, min_weight_fraction_leaf=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f777716f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6102246974155718\n",
      "Precision: 0.6102246974155718\n",
      "Recall: 0.6102246974155718\n",
      "F1 Score: 0.6102246974155718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Precision:\",precision_score(y_test, preds, average=\"micro\"))\n",
    "print(\"Recall:\",recall_score(y_test, preds,  average=\"micro\"))\n",
    "print(\"F1 Score:\",f1_score(y_test, preds,  average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f6e2a-edf8-4f53-81b1-ee2bca02eb94",
   "metadata": {},
   "source": [
    "#### KERAS-\n",
    "***\n",
    "##### Load the required libraries-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16915266-59ea-407b-9e54-d2d84b563a95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user-\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3a09bbf-55f1-4ea9-bb03-ea1ea5abab3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\user-\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikeras) (23.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikeras) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikeras) (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user-\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "WARNING:tensorflow:From C:\\Users\\User-\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'get_data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:948\u001b[0m\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# When constructing the global instances, we need to perform certain updates\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# by explicitly calling the superclass (dict.update, dict.items) to avoid\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# triggering resolution of _auto_backend_sentinel.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m rcParamsDefault \u001b[38;5;241m=\u001b[39m _rc_params_in_file(\n\u001b[1;32m--> 948\u001b[0m     cbook\u001b[38;5;241m.\u001b[39m_get_data_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlibrc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;66;03m# Strip leading comment.\u001b[39;00m\n\u001b[0;32m    950\u001b[0m     transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m line: line[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m line,\n\u001b[0;32m    951\u001b[0m     fail_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(rcParamsDefault, rcsetup\u001b[38;5;241m.\u001b[39m_hardcoded_defaults)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# Normally, the default matplotlibrc file contains *no* entry for backend (the\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;66;03m# corresponding line starts with ##, not #; we fill on _auto_backend_sentinel\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;66;03m# in that case.  However, packagers can set a different default backend\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;66;03m# (resulting in a normal `#backend: foo` line) in which case we should *not*\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;66;03m# fill in _auto_backend_sentinel.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\cbook\\__init__.py:556\u001b[0m, in \u001b[0;36m_get_data_path\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_data_path\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    551\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03m    Return the `pathlib.Path` to a resource file provided by Matplotlib.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m    ``*args`` specify a path relative to the base data path.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Path(matplotlib\u001b[38;5;241m.\u001b[39mget_data_path(), \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'get_data_path'"
     ]
    }
   ],
   "source": [
    "!pip install scikeras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be093c8e-8bf8-4a66-9f13-b8ad389e505a",
   "metadata": {},
   "source": [
    "##### Consider the initial train_set-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72d4b519-190a-45e3-b247-c9d82b3aa6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zero     954068\n",
       "Four     542922\n",
       "One      250698\n",
       "Three    203284\n",
       "Nine     200150\n",
       "Five     149606\n",
       "Two       97591\n",
       "Eight     46057\n",
       "Seven     46001\n",
       "Six       22554\n",
       "Name: new_hotel_cluster, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['new_hotel_cluster'].replace([0,1,2,3,4,5,6,7,8,9],  \n",
    "                               ['zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine'], \n",
    "                               inplace=True)\n",
    "train_set['new_hotel_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e338789-f212-4f92-81ab-b3dc0040bdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_k = train_set.drop(['new_hotel_cluster'], axis=1)\n",
    "y_train_k = train_set['new_hotel_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e9de4e5-7f97-4fcb-a01d-f5ab32f52211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_k)\n",
    "encoded_y = encoder.transform(y_train_k)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = keras.utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ad8191f-7353-496a-a544-064da0f99b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_traink, X_testk, y_traink, y_testk = train_test_split(X_train_k, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2fc4f20-2241-4657-82de-135b22a122f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scales data between 0 and 1\n",
    "X_traink = keras.utils.normalize(X_traink, axis=1)  \n",
    "X_testk = keras.utils.normalize(X_testk, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ecddf-3742-4710-b6e4-0c71c977043a",
   "metadata": {},
   "source": [
    "##### The Keras model-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a68cc86d-10b0-4279-843b-b3b881b1f60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c_model():\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(2048, activation='relu', input_dim=39))\n",
    "  # model.add(Dense(1024, activation='relu'))\n",
    "  # model.add(Dropout(0.25))\n",
    "  model.add(Dense(512, activation='relu'))\n",
    "  # model.add(Dropout(0.25))\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  # model.add(Dropout(0.25))\n",
    "  # model.add(Dense(128, activation='relu'))\n",
    "  # model.add(Dropout(0.25))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  # model.add(Dropout(0.5))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "  \n",
    "  model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e73ed8-d1af-4bbf-9174-5636769cfd28",
   "metadata": {},
   "source": [
    "##### a. For epochs=15, batch_size=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7f39337-26c0-4d36-ab20-1e4cff9cb79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\User-\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User-\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "101/101 [==============================] - 173s 1s/step - loss: 1.5032 - accuracy: 0.4463\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.6865 - accuracy: 0.7402\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.4030 - accuracy: 0.8627\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 136s 1s/step - loss: 0.4424 - accuracy: 0.8460\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1952 - accuracy: 0.9464\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.4803 - accuracy: 0.8520\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.2096 - accuracy: 0.9429\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1305 - accuracy: 0.9695\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1252 - accuracy: 0.9605\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.1272 - accuracy: 0.9534\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.5847 - accuracy: 0.8875\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1916 - accuracy: 0.9477\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1171 - accuracy: 0.9746\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.0943 - accuracy: 0.9793\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 123s 1s/step - loss: 0.0808 - accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function c_model at 0x0000025A36DB9580&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=20000\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=15\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function c_model at 0x0000025A36DB9580&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=20000\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=15\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=<function c_model at 0x0000025A36DB9580>\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=20000\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=15\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=c_model, epochs=15, batch_size=20000)\n",
    "model.fit(X_traink, y_traink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e0db5d3-fb1c-4316-97ad-d692b620d4ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 13s 386ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_testk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9809937e-d1ce-4000-b29f-fdc27f0a77d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9826955333106507\n",
      "Accuracy: 0.9826955333106507\n",
      "Precision: 0.9826955333106507\n",
      "Recall: 0.9826955333106507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print(\"F1 Score:\", f1_score(pred,y_testk, average=\"micro\"))\n",
    "print(\"Accuracy:\", accuracy_score(pred,y_testk))\n",
    "print(\"Precision:\",precision_score(pred,y_testk, average=\"micro\"))\n",
    "print(\"Recall:\",recall_score(pred,y_testk,  average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecdd0fc-e9fd-4ad1-b7a7-19b2c97b15c7",
   "metadata": {},
   "source": [
    "##### We have a very high accuracy here. This might be because the clusters aren't able to address the complexity in the data and are oversimplifying the dataset. Hence, k=10 is not a good approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
